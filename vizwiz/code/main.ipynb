{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import skimage\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from sklearn.utils.fixes import signature\n",
    "import time\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': 7501, 'train': 19502, 'val': 3001}\n"
     ]
    }
   ],
   "source": [
    "class AnswerDisDataset(Dataset):\n",
    "    def __init__(self, dataset_name, split):\n",
    "        super(AnswerDisDataset, self).__init__()\n",
    "        \n",
    "        self.image_dir = None\n",
    "        if dataset_name == 'vqa_2.0':\n",
    "            self.image_dir = '/home/qing/Desktop/Datasets/MSCOCO/images'\n",
    "        elif dataset_name == 'vizwiz':\n",
    "            self.image_dir = '/home/qing/Desktop/Datasets/VizWiz/v1/data/Images'\n",
    "        self.image_ext = '.jpg'\n",
    "        \n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'trainval': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "        }\n",
    "        \n",
    "        self.transform = data_transforms[split]\n",
    "        self.word2vocab_id = json.load(open('word2vocab_id.json'))\n",
    "        self.ans2id = json.load(open('ans2id.json'))\n",
    "        \n",
    "        dataroot='../data'\n",
    "        dataset = json.load(open(os.path.join(dataroot, '%s_%s.json'%(dataset_name, split))), encoding='cp1252')\n",
    "        max_length = 20\n",
    "        for sample in dataset:\n",
    "            question = sample['question']\n",
    "            question = question.lower()\n",
    "            tokens = nltk.word_tokenize(question)\n",
    "            tokens = [self.word2vocab_id[x] for x in tokens if x in self.word2vocab_id]\n",
    "            tokens = tokens[:max_length]\n",
    "            if len(tokens) < max_length:\n",
    "                # Note here we pad in front of the sentence\n",
    "                padding = [0] * (max_length - len(tokens))\n",
    "                tokens = padding + tokens\n",
    "            sample['q_token'] = tokens\n",
    "            \n",
    "            tokens = [x.lower() for x in sample['answers']]\n",
    "            tokens = [self.ans2id[x] for x in tokens if x in self.ans2id]\n",
    "            sample['a_token'] = tokens\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        entry = self.dataset[index]\n",
    "        image = entry['image']\n",
    "        image_path = os.path.join(self.image_dir, image.replace('.jpg', self.image_ext))\n",
    "        with open(image_path, 'rb') as f:\n",
    "            image = Image.open(f).convert('RGB')\n",
    "        label = [0 if x < 2 else 1 for x in entry['ans_dis_labels']]\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        question = torch.from_numpy(np.array(entry['q_token']))\n",
    "        answer = np.zeros((len(self.ans2id),), dtype=np.float32)\n",
    "        for ans in entry['a_token']:\n",
    "            answer[ans] += 1.0\n",
    "        answer /= 10.0\n",
    "        answer = torch.from_numpy(answer)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, question, answer, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "\n",
    "splits = ['train', 'val', 'test']\n",
    "datasets = {}\n",
    "datasets.update({x: AnswerDisDataset('vizwiz', x) for x in splits})\n",
    "dataset_sizes = {x: len(datasets[x]) for x in splits}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from language_model import WordEmbedding, QuestionEmbedding\n",
    "from fc import FCNet\n",
    "from torch.nn.utils.weight_norm import weight_norm\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Identity, self).__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "def init_image_model(init_model_path=None):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = Identity(num_ftrs)\n",
    "    \n",
    "    if init_model_path:\n",
    "        model.load_state_dict(torch.load(init_model_path))\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, w_emb, q_emb, q_net, v_net, a_net, classifier, model_type='Q+I'):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.w_emb = w_emb\n",
    "        self.q_emb = q_emb\n",
    "        self.q_net = q_net\n",
    "        self.v_net = v_net\n",
    "        self.a_net = a_net\n",
    "        self.classifier = classifier\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def forward(self, v, q, a):\n",
    "        \"\"\"Forward\n",
    "\n",
    "        return: logits, not probs\n",
    "        \"\"\"\n",
    "        w_emb = self.w_emb(q)\n",
    "        q_emb = self.q_emb(w_emb) # [batch, q_dim]\n",
    "\n",
    "        q_repr = self.q_net(q_emb)\n",
    "        v_repr = self.v_net(v)\n",
    "        a_repr = self.a_net(a)\n",
    "        \n",
    "        model_type = self.model_type\n",
    "        if model_type == 'I':\n",
    "            joint_repr = v_repr\n",
    "        elif model_type == 'Q':\n",
    "            joint_repr = q_repr\n",
    "        elif model_type == 'A':\n",
    "            joint_repr = a_repr\n",
    "        elif model_type == 'Q+I':\n",
    "            joint_repr = q_repr * v_repr\n",
    "        elif model_type == 'Q+I+A':\n",
    "            joint_repr = (q_repr + v_repr + a_repr) / 3\n",
    "        elif model_type == 'Q+A':\n",
    "            joint_repr = q_repr * a_repr\n",
    "        logits = self.classifier(joint_repr)\n",
    "        return logits\n",
    "    \n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, image_model, base_model):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.image_model = image_model\n",
    "        self.base_model = base_model\n",
    "        \n",
    "    def forward(self, img, q, a):\n",
    "        x = self.image_model(img)\n",
    "        x = self.base_model(x, q, a)\n",
    "        return x\n",
    "\n",
    "def init_model(model_type='Q+I'):\n",
    "    num_hid = 300\n",
    "    image_model = init_image_model()\n",
    "    w_emb = WordEmbedding(len(datasets['train'].word2vocab_id), 300, 0.0)\n",
    "    w_emb.init_embedding('glove6b_init_300d.npy')\n",
    "    q_emb = QuestionEmbedding(300, num_hid, 1, False, 0.0)\n",
    "    q_net = FCNet([num_hid, num_hid])\n",
    "    v_net = FCNet([image_model.fc.dim, num_hid])\n",
    "    a_net = FCNet([len(datasets['train'].ans2id), num_hid])\n",
    "    classifier = weight_norm(nn.Linear(num_hid, 10), dim=None)\n",
    "\n",
    "    base_model = BaseModel(w_emb, q_emb, q_net, v_net, a_net, classifier, model_type)\n",
    "    base_model = base_model.to(device)\n",
    "    model = FullModel(image_model, base_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval() \n",
    "    score_all = []\n",
    "    label_all = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for images, questions, answers, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        questions = questions.to(device)\n",
    "        labels = labels.to(device)\n",
    "        answers = answers.to(device)\n",
    "        outputs = model(images, questions, answers)\n",
    "        score_all.append(outputs.data.cpu().numpy())\n",
    "        label_all.append(labels.data.cpu().numpy())\n",
    "\n",
    "    score_all = np.concatenate(score_all, axis=0)\n",
    "    label_all = np.concatenate(label_all, axis=0)\n",
    "    #score_all[np.isnan(score_all)] = 0.\n",
    "    ap = average_precision_score(label_all, score_all, average=None)\n",
    "    \n",
    "    return ap, label_all, score_all\n",
    "\n",
    "def train_model(model, num_epochs=5, train_splits=['train'], \n",
    "                eval_splits=['test'], n_epochs_per_eval = 1):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    params = [{'params': model.base_model.parameters()}]\n",
    "    optimizer = optim.Adam(params, lr=1e-3)\n",
    "    # Decay LR by a factor of 0.1 every 100 epochs\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_ap = 0.0\n",
    "    \n",
    "    \n",
    "    train_dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4) for x in train_splits}\n",
    "    \n",
    "    eval_dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32,\n",
    "                                         shuffle=False, num_workers=4) for x in eval_splits}\n",
    "    \n",
    "    dataloaders = {}\n",
    "    dataloaders.update(train_dataloaders)\n",
    "    dataloaders.update(eval_dataloaders)\n",
    "    \n",
    "    ###########evaluate init model###########\n",
    "    for eval_split in eval_splits:\n",
    "        ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "        print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "        ap = np.mean(ap)\n",
    "        print(100*ap)\n",
    "    print()\n",
    "    #########################################\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        since = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for train_split in train_splits:\n",
    "            for images, questions, answers, labels in dataloaders[train_split]:\n",
    "                model.train()  # Set model to training mode\n",
    "                images = images.to(device)\n",
    "                questions = questions.to(device)\n",
    "                labels = labels.to(device)\n",
    "                answers = answers.to(device)\n",
    "                outputs = model(images, questions, answers)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # compute average precision\n",
    "        if (epoch+1) % n_epochs_per_eval == 0:\n",
    "            for eval_split in eval_splits:\n",
    "                ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "                print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "                ap = np.mean(ap)\n",
    "                print(100*ap)\n",
    "            # deep copy the model\n",
    "                \n",
    "            if ap > best_ap:\n",
    "                best_ap = ap\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Epoch time: {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        #print(flush=True)\n",
    "    \n",
    "    ###########evaluate final model###########\n",
    "    for eval_split in eval_splits:\n",
    "        ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "        print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "        ap = np.mean(ap)\n",
    "        print(100*ap)\n",
    "    # deep copy the model\n",
    "    if ap > best_ap:\n",
    "        best_ap = ap\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    print()\n",
    "    #########################################\n",
    "\n",
    "    print('Best val AP: {:2f}'.format(100*best_ap))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "(AP=[24.32 31.84 18.28  4.92 78.63  6.   66.81 77.63  1.62  0.82]) test\n",
      "31.08674423292475\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[51.56 49.25 28.67  6.76 82.25  8.34 78.34 85.45  1.63  0.41]) test\n",
      "39.2650905991656\n",
      "Epoch time: 3m 54s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[53.17 49.99 29.77  8.17 82.85  8.85 79.15 85.8   1.79  0.48]) test\n",
      "40.00175747234163\n",
      "Epoch time: 3m 53s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[54.18 50.39 29.77  7.62 83.38  8.93 79.41 85.97  1.82  0.54]) test\n",
      "40.200822311611724\n",
      "Epoch time: 3m 55s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[54.83 50.38 29.96  8.77 83.32  9.   79.57 86.13  1.7   0.57]) test\n",
      "40.42276496570785\n",
      "Epoch time: 3m 55s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[55.42 50.66 30.12  8.77 83.39  8.64 79.76 86.29  1.71  0.61]) test\n",
      "40.536735651667364\n",
      "Epoch time: 3m 54s\n",
      "(AP=[55.42 50.66 30.12  8.77 83.39  8.64 79.76 86.29  1.71  0.61]) test\n",
      "40.536735651667364\n",
      "\n",
      "Best val AP: 40.536736\n",
      "\n",
      "\n",
      "Q\n",
      "(AP=[22.14 34.64 16.67  5.15 72.43  6.06 64.03 71.99  1.49  0.45]) test\n",
      "29.505171556363518\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[35.53 53.78 37.    8.87 84.31  9.63 79.53 84.9   2.21  0.77]) test\n",
      "39.65291560605812\n",
      "Epoch time: 3m 53s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[35.87 54.66 39.24 12.32 84.41 11.   79.46 85.1   2.15  0.76]) test\n",
      "40.49752748490697\n",
      "Epoch time: 3m 53s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[35.97 54.21 38.57 13.48 84.33 10.95 79.55 85.11  1.86  0.73]) test\n",
      "40.47631864376313\n",
      "Epoch time: 3m 53s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[35.72 53.21 37.02 12.18 83.58 10.21 79.1  84.48  1.59  0.65]) test\n",
      "39.77625831551342\n",
      "Epoch time: 3m 55s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[35.73 52.9  35.48 12.36 82.87 10.57 79.01 84.18  1.77  0.89]) test\n",
      "39.57656807559808\n",
      "Epoch time: 3m 55s\n",
      "(AP=[35.73 52.9  35.48 12.36 82.87 10.57 79.01 84.18  1.77  0.89]) test\n",
      "39.57656807559808\n",
      "\n",
      "Best val AP: 40.497527\n",
      "\n",
      "\n",
      "Q+I\n",
      "(AP=[23.59 33.69 18.15  5.7  74.7   5.14 66.61 71.94  1.35  0.62]) test\n",
      "30.14957714365884\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[57.12 61.63 39.91  9.21 87.45 10.37 85.97 91.46  2.03  0.59]) test\n",
      "44.574940916480884\n",
      "Epoch time: 3m 54s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[57.81 62.47 43.24 13.77 87.81 11.14 86.36 92.01  2.    0.75]) test\n",
      "45.73488604127876\n",
      "Epoch time: 3m 54s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[56.95 62.   45.03 11.83 87.63 12.36 86.29 91.74  1.75  0.68]) test\n",
      "45.626763559638825\n",
      "Epoch time: 3m 54s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[57.26 61.98 44.7  13.84 87.32 11.37 86.02 91.8   1.78  0.71]) test\n",
      "45.67882897117024\n",
      "Epoch time: 3m 53s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[54.83 59.36 43.38 13.32 86.73 10.52 85.4  91.17  1.59  0.57]) test\n",
      "44.68530003352832\n",
      "Epoch time: 3m 54s\n",
      "(AP=[54.83 59.36 43.38 13.32 86.73 10.52 85.4  91.17  1.59  0.57]) test\n",
      "44.68530003352832\n",
      "\n",
      "Best val AP: 45.734886\n",
      "\n",
      "\n",
      "Q+A\n",
      "(AP=[33.56 36.52 16.16  5.01 74.53  4.85 59.69 72.6   1.57  0.76]) test\n",
      "30.52693309491769\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[65.28 77.85 57.41 10.55 88.79 10.1  90.1  95.22  1.77  1.66]) test\n",
      "49.87163319088108\n",
      "Epoch time: 3m 54s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[64.08 76.82 56.43 11.59 88.63  9.41 89.39 95.21  1.99  2.36]) test\n",
      "49.58969217801831\n",
      "Epoch time: 3m 53s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[62.72 74.62 54.74 11.54 88.66  9.31 89.24 95.12  2.21  1.61]) test\n",
      "48.97733893149219\n",
      "Epoch time: 3m 52s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[58.89 72.25 54.15 11.16 88.29  9.02 88.98 95.02  2.1   1.67]) test\n",
      "48.153441701751056\n",
      "Epoch time: 3m 53s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[58.91 70.56 52.38 10.96 88.29  9.15 88.76 94.89  2.02  1.37]) test\n",
      "47.73020996174336\n",
      "Epoch time: 3m 52s\n",
      "(AP=[58.91 70.56 52.38 10.96 88.29  9.15 88.76 94.89  2.02  1.37]) test\n",
      "47.73020996174336\n",
      "\n",
      "Best val AP: 49.871633\n",
      "\n",
      "\n",
      "A\n",
      "(AP=[47.92 35.58 19.15  5.82 82.59  5.95 70.33 82.41  1.61  0.4 ]) test\n",
      "35.17543229428205\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[64.12 77.2  55.92  8.97 88.3   7.16 89.79 94.65  1.68  2.18]) test\n",
      "48.99629340514099\n",
      "Epoch time: 3m 53s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[64.92 77.53 56.92  9.63 88.23  9.46 89.78 94.88  1.7   2.36]) test\n",
      "49.541694056491465\n",
      "Epoch time: 3m 53s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[65.26 77.69 57.14  9.62 88.63 10.   90.18 95.14  1.65  2.44]) test\n",
      "49.77538936428948\n",
      "Epoch time: 3m 54s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[65.35 77.84 57.38  9.8  88.96 10.2  90.14 95.18  1.65  2.34]) test\n",
      "49.88488132537896\n",
      "Epoch time: 3m 54s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[65.39 77.8  57.48  9.83 89.08 10.22 90.08 95.15  1.75  2.27]) test\n",
      "49.9045120479712\n",
      "Epoch time: 3m 53s\n",
      "(AP=[65.39 77.8  57.48  9.83 89.08 10.22 90.08 95.15  1.75  2.27]) test\n",
      "49.9045120479712\n",
      "\n",
      "Best val AP: 49.904512\n",
      "\n",
      "\n",
      "Q+I+A\n",
      "(AP=[22.97 32.15 16.54  4.48 77.94  6.15 68.65 71.37  1.51  0.6 ]) test\n",
      "30.235989415047083\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[65.58 77.42 56.54 10.49 89.7  11.26 90.42 95.44  1.98  1.31]) test\n",
      "50.01345384392606\n",
      "Epoch time: 3m 54s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[65.65 77.81 57.5  12.37 90.01 13.24 90.56 95.55  1.95  1.67]) test\n",
      "50.63338204138225\n",
      "Epoch time: 3m 54s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[66.25 77.71 57.2  13.55 90.01 12.46 90.53 95.51  1.96  1.62]) test\n",
      "50.678470997257264\n",
      "Epoch time: 3m 55s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[66.05 77.3  56.   14.3  90.   12.02 90.25 95.44  2.65  1.95]) test\n",
      "50.595642965136136\n",
      "Epoch time: 3m 54s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[65.5  76.87 54.35 13.55 89.32 11.57 89.95 95.1   2.55  2.04]) test\n",
      "50.07907049449195\n",
      "Epoch time: 3m 54s\n",
      "(AP=[65.5  76.87 54.35 13.55 89.32 11.57 89.95 95.1   2.55  2.04]) test\n",
      "50.07907049449195\n",
      "\n",
      "Best val AP: 50.678471\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_splits = ['train', 'val']\n",
    "model_type_list = ['I', 'Q', 'Q+I', 'Q+A', 'A', 'Q+I+A']\n",
    "eval_splits=['test']\n",
    "\n",
    "for model_type in model_type_list:\n",
    "    print(model_type)\n",
    "\n",
    "    model = init_model(model_type)\n",
    "    save_model_path = 'saved_models/{0}_train-on-({1}).pt'.format(model_type, ','.join(train_splits))\n",
    "    train_model(model, num_epochs=5, train_splits=train_splits, eval_splits=eval_splits, n_epochs_per_eval = 1)\n",
    "    torch.save(model.state_dict(), save_model_path)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "AP: [65.39 77.8  57.48  9.83 89.08 10.22 90.08 95.15  1.75  2.27]\n",
      "mAP: 49.904512048\n",
      "\n",
      "\n",
      "I\n",
      "AP: [55.42 50.66 30.12  8.77 83.39  8.64 79.76 86.29  1.71  0.61]\n",
      "mAP: 40.5367356517\n",
      "\n",
      "\n",
      "Q\n",
      "AP: [35.87 54.66 39.24 12.32 84.41 11.   79.46 85.1   2.15  0.76]\n",
      "mAP: 40.4975274849\n",
      "\n",
      "\n",
      "Q+I\n",
      "AP: [57.81 62.47 43.24 13.77 87.81 11.14 86.36 92.01  2.    0.75]\n",
      "mAP: 45.7348860413\n",
      "\n",
      "\n",
      "Q+A\n",
      "AP: [65.28 77.85 57.41 10.55 88.79 10.1  90.1  95.22  1.77  1.66]\n",
      "mAP: 49.8716331909\n",
      "\n",
      "\n",
      "Q+I+A\n",
      "AP: [66.25 77.71 57.2  13.55 90.01 12.46 90.53 95.51  1.96  1.62]\n",
      "mAP: 50.6784709973\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type_list = ['A', 'I', 'Q', 'Q+I', 'Q+A', 'Q+I+A']\n",
    "train_splits = ['train', 'val']\n",
    "eval_splits=['test']\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32,\n",
    "                                     shuffle=False, num_workers=4) for x in eval_splits}\n",
    "\n",
    "score_all = 0\n",
    "all_data= {}\n",
    "for model_type in model_type_list:\n",
    "    print(model_type)\n",
    "    model = init_model(model_type)\n",
    "    save_model_path = 'saved_models/{0}_train-on-({1}).pt'.format(model_type, ','.join(train_splits))\n",
    "    model.load_state_dict(torch.load(save_model_path))\n",
    "    \n",
    "    eval_split = eval_splits[0]\n",
    "    ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "    \n",
    "    key = '%s_train-on-%s_%s'%(model_type, ','.join(train_splits), eval_split)\n",
    "    value = [ap, label, score]\n",
    "    all_data[key] = value\n",
    "    \n",
    "    print('AP: {1}\\nmAP: {2}'.format(eval_split, 100*ap, 100*np.mean(ap)))\n",
    "    print('\\n')\n",
    "    \n",
    "    score_all += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.31"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.mean([44.82, 58.63,18.15,  5.7,  80.14,  5.14, 66.61, 71.94,  1.35,  0.62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AP=[61.28 76.64 56.05 11.94 89.65 12.09 90.26 94.92  2.04  1.09]) test\n",
      "49.59655459581514\n"
     ]
    }
   ],
   "source": [
    "score = [all_data['%s_train-on-%s_%s'%(model_type, ','.join(train_splits), eval_split)][2]\n",
    "         for model_type in ['A', 'Q']]\n",
    "score = sum(score)\n",
    "ap = average_precision_score(label, score, average=None)\n",
    "print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "ap = np.mean(ap)\n",
    "print(100*ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-6c81065af7b4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-6c81065af7b4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    LQI\tIVE\tINV\tDFF\tAMB\tSBJ\tSYN\tGRN\tSPM\tOTH\u001b[0m\n\u001b[0m       \t  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "LQI\tIVE\tINV\tDFF\tAMB\tSBJ\tSYN\tGRN\tSPM\tOTH\n",
    "7.89 56.53 38.25 25.78 96.37 24.97 87.92 83.27  5.39  0.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
