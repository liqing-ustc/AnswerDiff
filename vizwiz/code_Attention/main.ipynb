{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import skimage\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from sklearn.utils.fixes import signature\n",
    "import time\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "from attention import NewAttention\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': 7501, 'train': 19502, 'val': 3001}\n"
     ]
    }
   ],
   "source": [
    "class AnswerDisDataset(Dataset):\n",
    "    def __init__(self, dataset_name, split):\n",
    "        super(AnswerDisDataset, self).__init__()\n",
    "        \n",
    "        self.image_dir = None\n",
    "        if dataset_name == 'vqa_2.0':\n",
    "            self.image_dir = '/home/qing/Desktop/Datasets/MSCOCO/images'\n",
    "        elif dataset_name == 'vizwiz':\n",
    "            self.image_dir = '/home/qing/Desktop/Datasets/VizWiz/v1/data/Images'\n",
    "        self.image_ext = '.jpg'\n",
    "        \n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'trainval': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "        }\n",
    "        \n",
    "        self.transform = data_transforms[split]\n",
    "        self.word2vocab_id = json.load(open('word2vocab_id.json'))\n",
    "        self.ans2id = json.load(open('ans2id.json'))\n",
    "        \n",
    "        dataroot='../data'\n",
    "        dataset = json.load(open(os.path.join(dataroot, '%s_%s.json'%(dataset_name, split))), encoding='cp1252')\n",
    "        max_length = 20\n",
    "        for sample in dataset:\n",
    "            question = sample['question']\n",
    "            question = question.lower()\n",
    "            tokens = nltk.word_tokenize(question)\n",
    "            tokens = [self.word2vocab_id[x] for x in tokens if x in self.word2vocab_id]\n",
    "            tokens = tokens[:max_length]\n",
    "            if len(tokens) < max_length:\n",
    "                # Note here we pad in front of the sentence\n",
    "                padding = [0] * (max_length - len(tokens))\n",
    "                tokens = padding + tokens\n",
    "            sample['q_token'] = tokens\n",
    "            \n",
    "            tokens = [x.lower() for x in sample['answers']]\n",
    "            tokens = [self.ans2id[x] for x in tokens if x in self.ans2id]\n",
    "            sample['a_token'] = tokens\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        entry = self.dataset[index]\n",
    "        image = entry['image']\n",
    "        image_path = os.path.join(self.image_dir, image.replace('.jpg', self.image_ext))\n",
    "        with open(image_path, 'rb') as f:\n",
    "            image = Image.open(f).convert('RGB')\n",
    "        label = [0 if x < 2 else 1 for x in entry['ans_dis_labels']]\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        question = torch.from_numpy(np.array(entry['q_token']))\n",
    "        answer = np.zeros((len(self.ans2id),), dtype=np.float32)\n",
    "        for ans in entry['a_token']:\n",
    "            answer[ans] += 1.0\n",
    "        answer /= 10.0\n",
    "        answer = torch.from_numpy(answer)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, question, answer, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "\n",
    "splits = ['train', 'val', 'test']\n",
    "datasets = {}\n",
    "datasets.update({x: AnswerDisDataset('vizwiz', x) for x in splits})\n",
    "dataset_sizes = {x: len(datasets[x]) for x in splits}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from language_model import WordEmbedding, QuestionEmbedding\n",
    "from fc import FCNet\n",
    "from torch.nn.utils.weight_norm import weight_norm\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Identity, self).__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "def init_image_model(init_model_path=None):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.avgpool = Identity(num_ftrs)\n",
    "    model.fc = Identity(num_ftrs)\n",
    "    \n",
    "    \n",
    "    if init_model_path:\n",
    "        model.load_state_dict(torch.load(init_model_path))\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, w_emb, q_emb, v_att, q_net, v_net, a_net, classifier, model_type='Q+I'):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.w_emb = w_emb\n",
    "        self.q_emb = q_emb\n",
    "        self.v_att = v_att\n",
    "        self.q_net = q_net\n",
    "        self.v_net = v_net\n",
    "        self.a_net = a_net\n",
    "        self.classifier = classifier\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def forward(self, v, q, a):\n",
    "        \"\"\"Forward\n",
    "\n",
    "        return: logits, not probs\n",
    "        \"\"\"\n",
    "        w_emb = self.w_emb(q)\n",
    "        q_emb = self.q_emb(w_emb) # [batch, q_dim]\n",
    "\n",
    "        att = self.v_att(v, q_emb)\n",
    "        v_emb = (att * v).sum(1)\n",
    "        \n",
    "        q_repr = self.q_net(q_emb)\n",
    "        v_repr = self.v_net(v_emb)\n",
    "        a_repr = self.a_net(a)\n",
    "        \n",
    "        model_type = self.model_type\n",
    "        if model_type == 'I':\n",
    "            joint_repr = v_repr\n",
    "        elif model_type == 'Q':\n",
    "            joint_repr = q_repr\n",
    "        elif model_type == 'A':\n",
    "            joint_repr = a_repr\n",
    "        elif model_type == 'Q+I':\n",
    "            joint_repr = q_repr * v_repr\n",
    "        elif model_type == 'Q+I+A':\n",
    "            joint_repr = (q_repr + v_repr + a_repr) / 3\n",
    "        elif model_type == 'Q+A':\n",
    "            joint_repr = q_repr * a_repr\n",
    "        logits = self.classifier(joint_repr)\n",
    "        return logits\n",
    "    \n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, image_model, base_model):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.image_model = image_model\n",
    "        self.base_model = base_model\n",
    "        \n",
    "    def forward(self, img, q, a):\n",
    "        x = self.image_model(img)\n",
    "        x = x.view(x.size(0), -1, self.image_model.fc.dim)\n",
    "        x = self.base_model(x, q, a)\n",
    "        return x\n",
    "\n",
    "def init_model(model_type='Q+I'):\n",
    "    num_hid = 300\n",
    "    image_model = init_image_model()\n",
    "    v_dim = image_model.fc.dim\n",
    "    w_emb = WordEmbedding(len(datasets['train'].word2vocab_id), 300, 0.0)\n",
    "    w_emb.init_embedding('glove6b_init_300d.npy')\n",
    "    q_emb = QuestionEmbedding(300, num_hid, 1, False, 0.0)\n",
    "    v_att = NewAttention(v_dim, q_emb.num_hid, num_hid)\n",
    "    q_net = FCNet([num_hid, num_hid])\n",
    "    v_net = FCNet([image_model.fc.dim, num_hid])\n",
    "    a_net = FCNet([len(datasets['train'].ans2id), num_hid])\n",
    "    classifier = weight_norm(nn.Linear(num_hid, 10), dim=None)\n",
    "\n",
    "    base_model = BaseModel(w_emb, q_emb, v_att, q_net, v_net, a_net, classifier, model_type)\n",
    "    base_model = base_model.to(device)\n",
    "    model = FullModel(image_model, base_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval() \n",
    "    score_all = []\n",
    "    label_all = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for images, questions, answers, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        questions = questions.to(device)\n",
    "        labels = labels.to(device)\n",
    "        answers = answers.to(device)\n",
    "        outputs = model(images, questions, answers)\n",
    "        score_all.append(outputs.data.cpu().numpy())\n",
    "        label_all.append(labels.data.cpu().numpy())\n",
    "\n",
    "    score_all = np.concatenate(score_all, axis=0)\n",
    "    label_all = np.concatenate(label_all, axis=0)\n",
    "    #score_all[np.isnan(score_all)] = 0.\n",
    "    ap = average_precision_score(label_all, score_all, average=None)\n",
    "    \n",
    "    return ap, label_all, score_all\n",
    "\n",
    "def train_model(model, num_epochs=5, train_splits=['train'], \n",
    "                eval_splits=['test'], n_epochs_per_eval = 1):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    params = [{'params': model.base_model.parameters()}]\n",
    "    optimizer = optim.Adam(params, lr=1e-3)\n",
    "    # Decay LR by a factor of 0.1 every 100 epochs\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_ap = 0.0\n",
    "    \n",
    "    \n",
    "    train_dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4) for x in train_splits}\n",
    "    \n",
    "    eval_dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32,\n",
    "                                         shuffle=False, num_workers=4) for x in eval_splits}\n",
    "    \n",
    "    dataloaders = {}\n",
    "    dataloaders.update(train_dataloaders)\n",
    "    dataloaders.update(eval_dataloaders)\n",
    "    \n",
    "    ###########evaluate init model###########\n",
    "    for eval_split in eval_splits:\n",
    "        ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "        print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "        ap = np.mean(ap)\n",
    "        print(100*ap)\n",
    "    print()\n",
    "    #########################################\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        since = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for train_split in train_splits:\n",
    "            for images, questions, answers, labels in dataloaders[train_split]:\n",
    "                model.train()  # Set model to training mode\n",
    "                images = images.to(device)\n",
    "                questions = questions.to(device)\n",
    "                labels = labels.to(device)\n",
    "                answers = answers.to(device)\n",
    "                outputs = model(images, questions, answers)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # compute average precision\n",
    "        if (epoch+1) % n_epochs_per_eval == 0:\n",
    "            for eval_split in eval_splits:\n",
    "                ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "                print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "                ap = np.mean(ap)\n",
    "                print(100*ap)\n",
    "            # deep copy the model\n",
    "                \n",
    "            if ap > best_ap:\n",
    "                best_ap = ap\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Epoch time: {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        #print(flush=True)\n",
    "    \n",
    "    ###########evaluate final model###########\n",
    "    for eval_split in eval_splits:\n",
    "        ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "        print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "        ap = np.mean(ap)\n",
    "        print(100*ap)\n",
    "    # deep copy the model\n",
    "    if ap > best_ap:\n",
    "        best_ap = ap\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    print()\n",
    "    #########################################\n",
    "\n",
    "    print('Best val AP: {:2f}'.format(100*best_ap))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q+I\n",
      "(AP=[20.83 33.79 21.89  5.62 76.7   6.19 62.62 69.1   1.64  0.48]) test\n",
      "29.88550001007032\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[42.4  54.97 39.41  7.74 85.79  8.55 81.8  87.33  1.81  0.47]) test\n",
      "41.02492701963925\n",
      "Epoch time: 3m 55s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[45.22 56.93 42.32 10.05 86.28 10.92 83.34 89.05  1.68  0.56]) test\n",
      "42.63478506037281\n",
      "Epoch time: 3m 55s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[45.98 57.1  41.57 11.02 86.02 10.66 83.07 89.    1.67  0.78]) test\n",
      "42.68769475026315\n",
      "Epoch time: 3m 56s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[46.29 56.53 40.52 11.28 85.72 10.47 82.85 88.75  1.76  0.72]) test\n",
      "42.4886023627039\n",
      "Epoch time: 3m 55s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[46.11 57.01 40.59 11.67 85.33 10.82 82.46 88.38  1.69  0.72]) test\n",
      "42.47816894710813\n",
      "Epoch time: 3m 57s\n",
      "(AP=[46.11 57.01 40.59 11.67 85.33 10.82 82.46 88.38  1.69  0.72]) test\n",
      "42.47816894710813\n",
      "\n",
      "Best val AP: 42.687695\n",
      "\n",
      "\n",
      "Q+I+A\n",
      "(AP=[20.79 31.22 17.83  5.07 75.53  4.71 69.85 67.01  1.69  0.49]) test\n",
      "29.418365904300646\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[64.54 76.93 56.25  9.67 89.54 12.34 90.4  95.34  1.82  1.02]) test\n",
      "49.78575204685904\n",
      "Epoch time: 3m 55s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[64.93 77.4  56.78 10.1  89.48 13.16 90.52 95.5   1.84  1.28]) test\n",
      "50.09965935804823\n",
      "Epoch time: 3m 56s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[65.   77.56 56.39 10.68 89.65 11.93 90.39 95.44  1.86  1.72]) test\n",
      "50.06336790486363\n",
      "Epoch time: 3m 55s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[64.72 77.1  56.51 11.43 89.81 11.94 90.31 95.19  1.66  1.24]) test\n",
      "49.99098594022621\n",
      "Epoch time: 3m 55s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[64.33 76.53 55.53 12.22 89.13 11.18 89.93 94.99  1.61  1.02]) test\n",
      "49.64709371538394\n",
      "Epoch time: 3m 55s\n",
      "(AP=[64.33 76.53 55.53 12.22 89.13 11.18 89.93 94.99  1.61  1.02]) test\n",
      "49.64709371538394\n",
      "\n",
      "Best val AP: 50.099659\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_splits = ['train', 'val']\n",
    "model_type_list = ['Q+I', 'Q+I+A']\n",
    "eval_splits=['test']\n",
    "\n",
    "for model_type in model_type_list:\n",
    "    print(model_type)\n",
    "\n",
    "    model = init_model(model_type)\n",
    "    save_model_path = 'saved_models/{0}_train-on-({1}).pt'.format(model_type, ','.join(train_splits))\n",
    "    train_model(model, num_epochs=5, train_splits=train_splits, eval_splits=eval_splits, n_epochs_per_eval = 1)\n",
    "    torch.save(model.state_dict(), save_model_path)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q+I\n",
      "AP: [45.98 57.1  41.57 11.02 86.02 10.66 83.07 89.    1.67  0.78]\n",
      "mAP: 42.6876947503\n",
      "\n",
      "\n",
      "Q+I+A\n",
      "AP: [64.93 77.4  56.78 10.1  89.48 13.16 90.52 95.5   1.84  1.28]\n",
      "mAP: 50.099659358\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type_list = ['Q+I', 'Q+I+A']\n",
    "train_splits = ['train', 'val']\n",
    "eval_splits=['test']\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32,\n",
    "                                     shuffle=False, num_workers=4) for x in eval_splits}\n",
    "\n",
    "score_all = 0\n",
    "all_data= {}\n",
    "for model_type in model_type_list:\n",
    "    print(model_type)\n",
    "    model = init_model(model_type)\n",
    "    save_model_path = 'saved_models/{0}_train-on-({1}).pt'.format(model_type, ','.join(train_splits))\n",
    "    model.load_state_dict(torch.load(save_model_path))\n",
    "    \n",
    "    eval_split = eval_splits[0]\n",
    "    ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "    \n",
    "    key = '%s_train-on-%s_%s'%(model_type, ','.join(train_splits), eval_split)\n",
    "    value = [ap, label, score]\n",
    "    all_data[key] = value\n",
    "    \n",
    "    print('AP: {1}\\nmAP: {2}'.format(eval_split, 100*ap, 100*np.mean(ap)))\n",
    "    print('\\n')\n",
    "    \n",
    "    score_all += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " np.mean([44.82, 58.63,18.15,  5.7,  80.14,  5.14, 66.61, 71.94,  1.35,  0.62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = [all_data['%s_train-on-%s_%s'%(model_type, ','.join(train_splits), eval_split)][2]\n",
    "         for model_type in ['A', 'Q']]\n",
    "score = sum(score)\n",
    "ap = average_precision_score(label, score, average=None)\n",
    "print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "ap = np.mean(ap)\n",
    "print(100*ap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LQI\tIVE\tINV\tDFF\tAMB\tSBJ\tSYN\tGRN\tSPM\tOTH\n",
    "7.89 56.53 38.25 25.78 96.37 24.97 87.92 83.27  5.39  0.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
