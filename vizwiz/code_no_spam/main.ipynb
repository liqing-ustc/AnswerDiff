{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "import os\n",
    "import copy\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "import skimage\n",
    "from PIL import Image\n",
    "from copy import deepcopy\n",
    "from sklearn.utils.fixes import signature\n",
    "import time\n",
    "import pickle\n",
    "import nltk\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'test': 7501, 'train': 19502, 'val': 3001}\n"
     ]
    }
   ],
   "source": [
    "class AnswerDisDataset(Dataset):\n",
    "    def __init__(self, dataset_name, split):\n",
    "        super(AnswerDisDataset, self).__init__()\n",
    "        \n",
    "        self.image_dir = None\n",
    "        if dataset_name == 'vqa_2.0':\n",
    "            self.image_dir = '/home/qing/Desktop/Datasets/MSCOCO/images'\n",
    "        elif dataset_name == 'vizwiz':\n",
    "            self.image_dir = '/home/qing/Desktop/Datasets/VizWiz/v1/data/Images'\n",
    "        self.image_ext = '.jpg'\n",
    "        \n",
    "        data_transforms = {\n",
    "            'train': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'trainval': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.RandomHorizontalFlip(),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'val': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "            'test': transforms.Compose([\n",
    "                transforms.Resize((224, 224)),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "            ]),\n",
    "        }\n",
    "        \n",
    "        self.transform = data_transforms[split]\n",
    "        self.word2vocab_id = json.load(open('word2vocab_id.json'))\n",
    "        self.ans2id = json.load(open('ans2id.json'))\n",
    "        \n",
    "        dataroot='../data'\n",
    "        dataset = json.load(open(os.path.join(dataroot, '%s_%s.json'%(dataset_name, split))), encoding='cp1252')\n",
    "        max_length = 20\n",
    "        for sample in dataset:\n",
    "            question = sample['question']\n",
    "            question = question.lower()\n",
    "            tokens = nltk.word_tokenize(question)\n",
    "            tokens = [self.word2vocab_id[x] for x in tokens if x in self.word2vocab_id]\n",
    "            tokens = tokens[:max_length]\n",
    "            if len(tokens) < max_length:\n",
    "                # Note here we pad in front of the sentence\n",
    "                padding = [0] * (max_length - len(tokens))\n",
    "                tokens = padding + tokens\n",
    "            sample['q_token'] = tokens\n",
    "            \n",
    "            tokens = [x.lower() for x in sample['answers']]\n",
    "            tokens = [self.ans2id[x] for x in tokens if x in self.ans2id]\n",
    "            sample['a_token'] = tokens\n",
    "        self.dataset = dataset\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        entry = self.dataset[index]\n",
    "        image = entry['image']\n",
    "        image_path = os.path.join(self.image_dir, image.replace('.jpg', self.image_ext))\n",
    "        with open(image_path, 'rb') as f:\n",
    "            image = Image.open(f).convert('RGB')\n",
    "        label = [0 if x < 2 else 1 for x in entry['ans_dis_labels']]\n",
    "        label[-2] = 0 # -2 -> spam, don't consider it\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "        \n",
    "        question = torch.from_numpy(np.array(entry['q_token']))\n",
    "        answer = np.zeros((len(self.ans2id),), dtype=np.float32)\n",
    "        for ans in entry['a_token']:\n",
    "            answer[ans] += 1.0\n",
    "        answer /= 10.0\n",
    "        answer = torch.from_numpy(answer)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, question, answer, label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "    \n",
    "\n",
    "splits = ['train', 'val', 'test']\n",
    "datasets = {}\n",
    "datasets.update({x: AnswerDisDataset('vizwiz', x) for x in splits})\n",
    "dataset_sizes = {x: len(datasets[x]) for x in splits}\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from language_model import WordEmbedding, QuestionEmbedding\n",
    "from fc import FCNet\n",
    "from torch.nn.utils.weight_norm import weight_norm\n",
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super(Identity, self).__init__()\n",
    "        self.dim = dim\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "def init_image_model(init_model_path=None):\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    num_ftrs = model.fc.in_features\n",
    "    model.fc = Identity(num_ftrs)\n",
    "    \n",
    "    if init_model_path:\n",
    "        model.load_state_dict(torch.load(init_model_path))\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, w_emb, q_emb, q_net, v_net, a_net, classifier, model_type='Q+I'):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.w_emb = w_emb\n",
    "        self.q_emb = q_emb\n",
    "        self.q_net = q_net\n",
    "        self.v_net = v_net\n",
    "        self.a_net = a_net\n",
    "        self.classifier = classifier\n",
    "        self.model_type = model_type\n",
    "\n",
    "    def forward(self, v, q, a):\n",
    "        \"\"\"Forward\n",
    "\n",
    "        return: logits, not probs\n",
    "        \"\"\"\n",
    "        w_emb = self.w_emb(q)\n",
    "        q_emb = self.q_emb(w_emb) # [batch, q_dim]\n",
    "\n",
    "        q_repr = self.q_net(q_emb)\n",
    "        v_repr = self.v_net(v)\n",
    "        a_repr = self.a_net(a)\n",
    "        \n",
    "        model_type = self.model_type\n",
    "        if model_type == 'I':\n",
    "            joint_repr = v_repr\n",
    "        elif model_type == 'Q':\n",
    "            joint_repr = q_repr\n",
    "        elif model_type == 'A':\n",
    "            joint_repr = a_repr\n",
    "        elif model_type == 'Q+I':\n",
    "            joint_repr = q_repr * v_repr\n",
    "        elif model_type == 'Q+I+A':\n",
    "            joint_repr = (q_repr + v_repr + a_repr) / 3\n",
    "        elif model_type == 'Q+A':\n",
    "            joint_repr = q_repr * a_repr\n",
    "        logits = self.classifier(joint_repr)\n",
    "        return logits\n",
    "    \n",
    "class FullModel(nn.Module):\n",
    "    def __init__(self, image_model, base_model):\n",
    "        super(FullModel, self).__init__()\n",
    "        self.image_model = image_model\n",
    "        self.base_model = base_model\n",
    "        \n",
    "    def forward(self, img, q, a):\n",
    "        x = self.image_model(img)\n",
    "        x = self.base_model(x, q, a)\n",
    "        return x\n",
    "\n",
    "def init_model(model_type='Q+I'):\n",
    "    num_hid = 300\n",
    "    image_model = init_image_model()\n",
    "    w_emb = WordEmbedding(len(datasets['train'].word2vocab_id), 300, 0.0)\n",
    "    w_emb.init_embedding('glove6b_init_300d.npy')\n",
    "    q_emb = QuestionEmbedding(300, num_hid, 1, False, 0.0)\n",
    "    q_net = FCNet([num_hid, num_hid])\n",
    "    v_net = FCNet([image_model.fc.dim, num_hid])\n",
    "    a_net = FCNet([len(datasets['train'].ans2id), num_hid])\n",
    "    classifier = weight_norm(nn.Linear(num_hid, 10), dim=None)\n",
    "\n",
    "    base_model = BaseModel(w_emb, q_emb, q_net, v_net, a_net, classifier, model_type)\n",
    "    base_model = base_model.to(device)\n",
    "    model = FullModel(image_model, base_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval() \n",
    "    score_all = []\n",
    "    label_all = []\n",
    "\n",
    "    # Iterate over data.\n",
    "    for images, questions, answers, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        questions = questions.to(device)\n",
    "        labels = labels.to(device)\n",
    "        answers = answers.to(device)\n",
    "        outputs = model(images, questions, answers)\n",
    "        score_all.append(outputs.data.cpu().numpy())\n",
    "        label_all.append(labels.data.cpu().numpy())\n",
    "\n",
    "    score_all = np.concatenate(score_all, axis=0)\n",
    "    label_all = np.concatenate(label_all, axis=0)\n",
    "    #score_all[np.isnan(score_all)] = 0.\n",
    "    ap = average_precision_score(label_all, score_all, average=None)\n",
    "    \n",
    "    return ap, label_all, score_all\n",
    "\n",
    "def train_model(model, num_epochs=5, train_splits=['train'], \n",
    "                eval_splits=['test'], n_epochs_per_eval = 1):\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    params = [{'params': model.base_model.parameters()}]\n",
    "    optimizer = optim.Adam(params, lr=1e-3)\n",
    "    # Decay LR by a factor of 0.1 every 100 epochs\n",
    "    scheduler = lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.1)\n",
    "    \n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_ap = 0.0\n",
    "    \n",
    "    \n",
    "    train_dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32,\n",
    "                                             shuffle=True, num_workers=4) for x in train_splits}\n",
    "    \n",
    "    eval_dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32,\n",
    "                                         shuffle=False, num_workers=4) for x in eval_splits}\n",
    "    \n",
    "    dataloaders = {}\n",
    "    dataloaders.update(train_dataloaders)\n",
    "    dataloaders.update(eval_dataloaders)\n",
    "    \n",
    "    ###########evaluate init model###########\n",
    "    for eval_split in eval_splits:\n",
    "        ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "        print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "        ap = np.nanmean(ap)\n",
    "        print(100*ap)\n",
    "    print()\n",
    "    #########################################\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        since = time.time()\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        running_corrects = 0\n",
    "\n",
    "        # Iterate over data.\n",
    "        for train_split in train_splits:\n",
    "            for images, questions, answers, labels in dataloaders[train_split]:\n",
    "                model.train()  # Set model to training mode\n",
    "                images = images.to(device)\n",
    "                questions = questions.to(device)\n",
    "                labels = labels.to(device)\n",
    "                answers = answers.to(device)\n",
    "                outputs = model(images, questions, answers)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "        # compute average precision\n",
    "        if (epoch+1) % n_epochs_per_eval == 0:\n",
    "            for eval_split in eval_splits:\n",
    "                ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "                print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "                ap = np.nanmean(ap)\n",
    "                print(100*ap)\n",
    "            # deep copy the model\n",
    "                \n",
    "            if ap > best_ap:\n",
    "                best_ap = ap\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        time_elapsed = time.time() - since\n",
    "        print('Epoch time: {:.0f}m {:.0f}s'.format(\n",
    "            time_elapsed // 60, time_elapsed % 60))\n",
    "        #print(flush=True)\n",
    "    \n",
    "    ###########evaluate final model###########\n",
    "    for eval_split in eval_splits:\n",
    "        ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "        print('(AP={1}) {0}'.format(eval_split, 100*ap))\n",
    "        ap = np.nanmean(ap)\n",
    "        print(100*ap)\n",
    "    # deep copy the model\n",
    "    if ap > best_ap:\n",
    "        best_ap = ap\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    print()\n",
    "    #########################################\n",
    "\n",
    "    print('Best val AP: {:2f}'.format(100*best_ap))\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I\n",
      "(AP=[26.77 37.73 16.27  4.67 73.67  5.67 67.67 75.24   nan  0.4 ]) test\n",
      "34.23283425319277\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qing/anaconda2/lib/python2.7/site-packages/sklearn/metrics/ranking.py:526: RuntimeWarning: invalid value encountered in true_divide\n",
      "  recall = tps / tps[-1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(AP=[52.85 49.39 28.51  6.88 82.39  8.7  78.93 85.52   nan  0.4 ]) test\n",
      "43.73088021129832\n",
      "Epoch time: 6m 52s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[53.91 50.03 29.78  7.84 83.17  8.71 79.16 85.86   nan  0.49]) test\n",
      "44.32611540855959\n",
      "Epoch time: 3m 52s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[54.92 50.37 29.93  7.78 83.11  8.81 79.62 85.99   nan  0.43]) test\n",
      "44.55162305455126\n",
      "Epoch time: 3m 53s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[55.23 50.38 29.85  8.17 83.42  9.19 79.96 86.34   nan  0.62]) test\n",
      "44.79421825476641\n",
      "Epoch time: 3m 54s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[55.42 50.95 29.91  8.05 83.34  8.72 79.78 86.04   nan  0.56]) test\n",
      "44.753949298886376\n",
      "Epoch time: 3m 53s\n",
      "(AP=[55.42 50.95 29.91  8.05 83.34  8.72 79.78 86.04   nan  0.56]) test\n",
      "44.753949298886376\n",
      "\n",
      "Best val AP: 44.794218\n",
      "\n",
      "\n",
      "Q\n",
      "(AP=[26.26 35.   20.14  5.07 74.17  5.14 62.45 74.97   nan  0.53]) test\n",
      "33.748423498377136\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[34.01 53.77 38.3   9.02 84.41 10.17 79.6  85.02   nan  0.67]) test\n",
      "43.88639239935925\n",
      "Epoch time: 3m 52s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[35.38 54.43 38.91 13.59 84.44 10.59 79.68 85.15   nan  0.65]) test\n",
      "44.75726713163825\n",
      "Epoch time: 3m 52s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[35.86 54.18 38.93 13.18 84.36 10.85 79.33 84.88   nan  0.6 ]) test\n",
      "44.68453109200372\n",
      "Epoch time: 3m 52s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[35.72 53.3  36.84 12.63 83.91 10.71 79.07 84.39   nan  0.66]) test\n",
      "44.13773111671201\n",
      "Epoch time: 3m 53s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[35.47 52.76 35.87 11.95 82.89  9.9  78.08 83.44   nan  0.6 ]) test\n",
      "43.44037325336678\n",
      "Epoch time: 3m 53s\n",
      "(AP=[35.47 52.76 35.87 11.95 82.89  9.9  78.08 83.44   nan  0.6 ]) test\n",
      "43.44037325336678\n",
      "\n",
      "Best val AP: 44.757267\n",
      "\n",
      "\n",
      "Q+I\n",
      "(AP=[22.86 41.28 18.24  5.65 74.28  5.92 67.23 71.19   nan  0.52]) test\n",
      "34.13053770945346\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[56.49 61.38 41.15  9.42 87.4  10.49 85.89 91.49   nan  0.6 ]) test\n",
      "49.368585603304396\n",
      "Epoch time: 3m 52s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[56.71 62.05 45.35 11.9  87.69 11.41 86.34 91.7    nan  0.59]) test\n",
      "50.416301425407674\n",
      "Epoch time: 3m 53s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[56.54 61.91 45.25 13.8  87.55 11.55 85.97 91.42   nan  1.36]) test\n",
      "50.593488638627335\n",
      "Epoch time: 3m 54s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[55.87 61.7  44.36 14.18 87.44  9.83 86.3  91.5    nan  0.81]) test\n",
      "50.22042493703156\n",
      "Epoch time: 3m 54s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[54.75 60.95 43.68 12.45 86.75 10.43 85.68 91.02   nan  0.64]) test\n",
      "49.594803736685364\n",
      "Epoch time: 3m 53s\n",
      "(AP=[54.75 60.95 43.68 12.45 86.75 10.43 85.68 91.02   nan  0.64]) test\n",
      "49.594803736685364\n",
      "\n",
      "Best val AP: 50.593489\n",
      "\n",
      "\n",
      "Q+A\n",
      "(AP=[28.52 32.55 13.59  5.48 78.38  5.7  54.15 82.16   nan  0.34]) test\n",
      "33.43030093988602\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[65.21 77.7  57.37 10.89 88.76  9.8  90.05 95.26   nan  2.09]) test\n",
      "55.23666484312082\n",
      "Epoch time: 3m 51s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[63.98 76.27 57.27 11.76 88.61  9.71 89.31 95.08   nan  2.07]) test\n",
      "54.894483835674436\n",
      "Epoch time: 3m 53s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[62.47 74.27 55.01 11.3  88.29  9.29 89.02 95.08   nan  1.71]) test\n",
      "54.048693759232634\n",
      "Epoch time: 3m 51s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[60.75 73.07 53.47 11.26 88.2   9.25 88.93 95.     nan  1.33]) test\n",
      "53.47376180645789\n",
      "Epoch time: 3m 52s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[59.64 72.12 52.74 11.14 88.17  9.41 88.83 94.99   nan  1.38]) test\n",
      "53.15781981821159\n",
      "Epoch time: 3m 52s\n",
      "(AP=[59.64 72.12 52.74 11.14 88.17  9.41 88.83 94.99   nan  1.38]) test\n",
      "53.15781981821159\n",
      "\n",
      "Best val AP: 55.236665\n",
      "\n",
      "\n",
      "A\n",
      "(AP=[18.75 29.67 10.67  3.83 76.21  5.13 66.47 83.71   nan  0.51]) test\n",
      "32.772117482236055\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[64.56 77.14 55.96  8.97 88.06  7.31 89.85 94.53   nan  2.83]) test\n",
      "54.35589116795631\n",
      "Epoch time: 3m 52s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[64.97 77.61 56.82  9.55 88.25  9.44 89.97 94.72   nan  2.44]) test\n",
      "54.86337647695686\n",
      "Epoch time: 3m 52s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[65.17 77.68 57.21  9.85 88.7   9.99 90.12 95.06   nan  2.42]) test\n",
      "55.135922990741136\n",
      "Epoch time: 3m 52s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[65.29 77.72 57.27  9.9  88.93 10.03 90.15 95.2    nan  2.54]) test\n",
      "55.22596920701718\n",
      "Epoch time: 3m 51s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[65.35 77.76 57.4   9.75 89.21 10.17 90.19 95.31   nan  2.51]) test\n",
      "55.295288460067894\n",
      "Epoch time: 3m 51s\n",
      "(AP=[65.35 77.76 57.4   9.75 89.21 10.17 90.19 95.31   nan  2.51]) test\n",
      "55.295288460067894\n",
      "\n",
      "Best val AP: 55.295288\n",
      "\n",
      "\n",
      "Q+I+A\n",
      "(AP=[19.63 31.53 17.98  5.34 72.69  5.58 64.41 71.13   nan  1.44]) test\n",
      "32.19208665493264\n",
      "\n",
      "Epoch 0/4\n",
      "----------\n",
      "(AP=[65.51 77.36 55.76 10.38 89.77 10.83 90.39 95.5    nan  1.14]) test\n",
      "55.18250274936396\n",
      "Epoch time: 3m 53s\n",
      "Epoch 1/4\n",
      "----------\n",
      "(AP=[65.72 77.32 55.87 12.13 89.97 12.53 90.49 95.52   nan  1.97]) test\n",
      "55.72497617359002\n",
      "Epoch time: 3m 53s\n",
      "Epoch 2/4\n",
      "----------\n",
      "(AP=[66.03 77.8  56.55 12.94 90.03 12.51 90.41 95.51   nan  1.97]) test\n",
      "55.97179050992448\n",
      "Epoch time: 3m 53s\n",
      "Epoch 3/4\n",
      "----------\n",
      "(AP=[66.02 77.9  55.82 14.29 90.02 12.   90.2  95.36   nan  1.16]) test\n",
      "55.86458801251197\n",
      "Epoch time: 3m 54s\n",
      "Epoch 4/4\n",
      "----------\n",
      "(AP=[65.3  77.18 54.19 14.24 89.6  11.32 89.99 95.24   nan  1.07]) test\n",
      "55.348218479094044\n",
      "Epoch time: 3m 53s\n",
      "(AP=[65.3  77.18 54.19 14.24 89.6  11.32 89.99 95.24   nan  1.07]) test\n",
      "55.348218479094044\n",
      "\n",
      "Best val AP: 55.971791\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_splits = ['train', 'val']\n",
    "model_type_list = ['I', 'Q', 'Q+I', 'Q+A', 'A', 'Q+I+A']\n",
    "eval_splits=['test']\n",
    "\n",
    "for model_type in model_type_list:\n",
    "    print(model_type)\n",
    "\n",
    "    model = init_model(model_type)\n",
    "    save_model_path = 'saved_models/{0}_train-on-({1}).pt'.format(model_type, ','.join(train_splits))\n",
    "    train_model(model, num_epochs=5, train_splits=train_splits, eval_splits=eval_splits, n_epochs_per_eval = 1)\n",
    "    torch.save(model.state_dict(), save_model_path)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A\n",
      "AP: [65.35 77.76 57.4   9.75 89.21 10.17 90.19 95.31   nan  2.51]\n",
      "mAP: 55.2952884601\n",
      "\n",
      "\n",
      "I\n",
      "AP: [55.23 50.38 29.85  8.17 83.42  9.19 79.96 86.34   nan  0.62]\n",
      "mAP: 44.7942182548\n",
      "\n",
      "\n",
      "Q\n",
      "AP: [35.38 54.43 38.91 13.59 84.44 10.59 79.68 85.15   nan  0.65]\n",
      "mAP: 44.7572671316\n",
      "\n",
      "\n",
      "Q+I\n",
      "AP: [56.54 61.91 45.25 13.8  87.55 11.55 85.97 91.42   nan  1.36]\n",
      "mAP: 50.5934886386\n",
      "\n",
      "\n",
      "Q+A\n",
      "AP: [65.21 77.7  57.37 10.89 88.76  9.8  90.05 95.26   nan  2.09]\n",
      "mAP: 55.2366648431\n",
      "\n",
      "\n",
      "Q+I+A\n",
      "AP: [66.03 77.8  56.55 12.94 90.03 12.51 90.41 95.51   nan  1.97]\n",
      "mAP: 55.9717905099\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_type_list = ['A', 'I', 'Q', 'Q+I', 'Q+A', 'Q+I+A']\n",
    "train_splits = ['train', 'val']\n",
    "eval_splits=['test']\n",
    "\n",
    "dataloaders = {x: torch.utils.data.DataLoader(datasets[x], batch_size=32,\n",
    "                                     shuffle=False, num_workers=4) for x in eval_splits}\n",
    "\n",
    "score_all = 0\n",
    "all_data= {}\n",
    "for model_type in model_type_list:\n",
    "    print(model_type)\n",
    "    model = init_model(model_type)\n",
    "    save_model_path = 'saved_models/{0}_train-on-({1}).pt'.format(model_type, ','.join(train_splits))\n",
    "    model.load_state_dict(torch.load(save_model_path))\n",
    "    \n",
    "    eval_split = eval_splits[0]\n",
    "    ap, label, score = evaluate_model(model, dataloaders[eval_split])\n",
    "    \n",
    "    key = '%s_train-on-%s_%s'%(model_type, ','.join(train_splits), eval_split)\n",
    "    value = [ap, label, score]\n",
    "    all_data[key] = value\n",
    "    \n",
    "    print('AP: {1}\\nmAP: {2}'.format(eval_split, 100*ap, 100*np.nanmean(ap)))\n",
    "    print('\\n')\n",
    "    \n",
    "    score_all += score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35.31"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " np.mean([44.82, 58.63,18.15,  5.7,  80.14,  5.14, 66.61, 71.94,  1.35,  0.62])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-6c81065af7b4>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-6c81065af7b4>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    LQI\tIVE\tINV\tDFF\tAMB\tSBJ\tSYN\tGRN\tSPM\tOTH\u001b[0m\n\u001b[0m       \t  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "LQI\tIVE\tINV\tDFF\tAMB\tSBJ\tSYN\tGRN\tSPM\tOTH\n",
    "7.89 56.53 38.25 25.78 96.37 24.97 87.92 83.27  5.39  0.4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
